{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Shifoue/Segmentation/blob/main/UNET.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/Shifoue/Portfolio.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ujrwGtgr68UK",
        "outputId": "89722a4a-6f1f-4712-94da-65aacb9a4d32"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'Portfolio' already exists and is not an empty directory.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cd Portfolio/Eye_Segmentation_Project/"
      ],
      "metadata": {
        "id": "wB7z4p2s7OEF"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install utils\n",
        "!pip install torchmetrics"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kDb5taucKa2Z",
        "outputId": "8aec1cc8-6a0e-472f-d725-2020cdea70e8"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: utils in /usr/local/lib/python3.10/dist-packages (1.0.2)\n",
            "Requirement already satisfied: torchmetrics in /usr/local/lib/python3.10/dist-packages (1.3.2)\n",
            "Requirement already satisfied: numpy>1.20.0 in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (1.25.2)\n",
            "Requirement already satisfied: packaging>17.1 in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (24.0)\n",
            "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (2.2.1+cu121)\n",
            "Requirement already satisfied: lightning-utilities>=0.8.0 in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (0.11.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from lightning-utilities>=0.8.0->torchmetrics) (67.7.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from lightning-utilities>=0.8.0->torchmetrics) (4.10.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->torchmetrics) (3.13.3)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->torchmetrics) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->torchmetrics) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->torchmetrics) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->torchmetrics) (2023.6.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->torchmetrics) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->torchmetrics) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->torchmetrics) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->torchmetrics) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->torchmetrics) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->torchmetrics) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->torchmetrics) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->torchmetrics) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->torchmetrics) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->torchmetrics) (2.19.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->torchmetrics) (12.1.105)\n",
            "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->torchmetrics) (2.2.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.10.0->torchmetrics) (12.4.127)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->torchmetrics) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10.0->torchmetrics) (1.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip Dataset_Faces_training.zip\n",
        "!unzip Dataset_Faces_validation.zip\n",
        "\n",
        "!unzip Dataset_Faces_Mask_training.zip\n",
        "!unzip Dataset_Faces_Mask_validation.zip"
      ],
      "metadata": {
        "id": "-z7JswNTJhfo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9abbe286-99fa-4405-a66e-1def14b8b88b"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "unzip:  cannot find or open Dataset_Faces_training.zip, Dataset_Faces_training.zip.zip or Dataset_Faces_training.zip.ZIP.\n",
            "unzip:  cannot find or open Dataset_Faces_validation.zip, Dataset_Faces_validation.zip.zip or Dataset_Faces_validation.zip.ZIP.\n",
            "unzip:  cannot find or open Dataset_Faces_Mask_training.zip, Dataset_Faces_Mask_training.zip.zip or Dataset_Faces_Mask_training.zip.ZIP.\n",
            "unzip:  cannot find or open Dataset_Faces_Mask_validation.zip, Dataset_Faces_Mask_validation.zip.zip or Dataset_Faces_Mask_validation.zip.ZIP.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "gR8x9-8GdVo1"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class DoubleConv(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super(DoubleConv, self).__init__()\n",
        "        self.depht = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, out_channels, 3, 1, 1, bias=False),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(out_channels, out_channels, 3, 1, 1, bias=False),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU(inplace=True),\n",
        "        )\n",
        "\n",
        "    def forward(self, X):\n",
        "        return self.depht(X)\n",
        "\n",
        "class myUNET(nn.Module):\n",
        "    def __init__(self, in_channels=3, out_channels=1, features=[64, 128, 256, 512]):\n",
        "      super(myUNET, self).__init__()\n",
        "      self.encode = nn.ModuleList()\n",
        "      self.decode = nn.ModuleList()\n",
        "      self.pool = nn.MaxPool2d(kernel_size=2, stride=2) #divide size per 2\n",
        "\n",
        "      # Encode\n",
        "      for feature in features:\n",
        "          self.encode.append(DoubleConv(in_channels, feature))\n",
        "          in_channels = feature\n",
        "\n",
        "      # Decode\n",
        "      for feature in reversed(features):\n",
        "          self.decode.append(nn.ConvTranspose2d(feature*2, feature, kernel_size=2, stride=2))\n",
        "          self.decode.append(DoubleConv(feature*2, feature))\n",
        "\n",
        "      self.bottleneck = DoubleConv(features[-1], features[-1]*2)\n",
        "      self.final_conv = nn.Conv2d(features[0], out_channels, kernel_size=1)\n",
        "\n",
        "    def forward(self, X):\n",
        "        skip_connections = []\n",
        "\n",
        "        for depht in self.encode:\n",
        "            X = depht(X)\n",
        "            skip_connections.append(X)\n",
        "            X = self.pool(X)\n",
        "\n",
        "        X = self.bottleneck(X)\n",
        "        skip_connections = skip_connections[::-1]\n",
        "\n",
        "        for i in range(0, len(self.decode), 2):\n",
        "            X = self.decode[i](X)\n",
        "            #skip_connection = skip_connections[-1 - i//2]\n",
        "            skip_connection = skip_connections[i//2]\n",
        "\n",
        "            if X.shape != skip_connection.shape:\n",
        "                X = torch.nn.functional.interpolate(X, size=skip_connection.shape[2:])\n",
        "\n",
        "            concat_skip = torch.cat((skip_connection, X), dim=1)\n",
        "            X = self.decode[i+1](concat_skip)\n",
        "\n",
        "        return self.final_conv(X)\n",
        "\n",
        "def test():\n",
        "    x = torch.randn((3, 1, 160, 160))\n",
        "    m = myUNET(in_channels=1, out_channels=1)\n",
        "    pred = m(x)\n",
        "\n",
        "    assert pred.shape == x.shape\n",
        "\n",
        "test()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from PIL import Image\n",
        "from torch.utils.data import Dataset\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "XMPeoxb_xUTV"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class FaceDataset(Dataset):\n",
        "    def __init__(self, image_dir, mask_dir, transform=None):\n",
        "        self.image_dir = image_dir\n",
        "        self.mask_dir = mask_dir\n",
        "        self.transform = transform\n",
        "        self.images = os.listdir(image_dir)\n",
        "        self.masks = os.listdir(mask_dir)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.images)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        image_path = os.path.join(self.image_dir, self.images[index])\n",
        "        mask_path = os.path.join(self.mask_dir, self.masks[index])\n",
        "        image = Image.open(image_path).convert(\"RGB\")\n",
        "        mask = Image.open(mask_path).convert(\"L\") #, dtype=np.float32)\n",
        "\n",
        "        #mask[mask == 255.0] = 1.0\n",
        "        #mask = mask/255.0\n",
        "\n",
        "        if self.transform is not None:\n",
        "\n",
        "            #augmentations = self.transform(image=image, mask=mask)\n",
        "            image = self.transform(image) #augmentations[\"image\"]\n",
        "            mask = self.transform(mask) #augmentations[\"mask\"]\n",
        "            mask = (mask > 0.5).float()\n",
        "\n",
        "        return image, mask"
      ],
      "metadata": {
        "id": "8xy32iIVxy-h"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ZswELlbr01Id"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "YPVXNS6mo6mn"
      },
      "outputs": [],
      "source": [
        "import albumentations as A\n",
        "from albumentations.pytorch import ToTensorV2\n",
        "from tqdm import tqdm\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6uT8RpNPK-vU"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Hyperparamters\n",
        "\n",
        "LEARNING_RATE = 1e-4\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "BATCH_SIZE = 16\n",
        "NUM_EPOCHS = 30\n",
        "NUM_WORKERS = 2\n",
        "IMAGE_HEIGHT = 218\n",
        "IMAGE_WIDTH = 178\n",
        "PIN_MEMORY = True\n",
        "LOAD_MODEL = True\n",
        "IMG_DIR_TRAIN = \"/content/Portfolio/Eye_Segmentation_Project/Dataset_Faces_training\"\n",
        "IMG_DIR_VAL = \"/content/Portfolio/Eye_Segmentation_Project/Dataset_Faces_validation\"\n",
        "MASK_DIR_TRAIN = \"/content/Portfolio/Eye_Segmentation_Project/Dataset_Faces_Mask_training\"\n",
        "MASK_DIR_VAL = \"/content/Portfolio/Eye_Segmentation_Project/Dataset_Faces_Mask_validation\"\n",
        "SAVE_DIR = \"Saved_Images\""
      ],
      "metadata": {
        "id": "gme7GcrQ4wXv"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2"
      ],
      "metadata": {
        "id": "P6ziMvsKOTXp"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "def save_checkpoint(state, filename=\"checkpoint.pth.tar\"):\n",
        "    print(\"=> Saving checkpoint\")\n",
        "    torch.save(state, filename)\n",
        "\n",
        "def load_checkpoint(checkpoint, model):\n",
        "    print(\"=> Loading checkpoint\")\n",
        "    model.load_state_dict(checkpoint[\"state_dict\"])\n",
        "\n",
        "def get_loaders(\n",
        "    train_dir,\n",
        "    train_mask_dir,\n",
        "    val_dir,\n",
        "    val_mask_dir,\n",
        "    batch_size,\n",
        "    train_transform,\n",
        "    val_transform,\n",
        "    num_workers=4,\n",
        "    pin_memory=True\n",
        "):\n",
        "    train_data = FaceDataset(image_dir=train_dir, mask_dir=train_mask_dir, transform = train_transform)\n",
        "    train_loader = DataLoader(train_data, batch_size=batch_size, num_workers=num_workers, pin_memory=pin_memory, shuffle=True)\n",
        "\n",
        "    val_data = FaceDataset(image_dir=val_dir, mask_dir=val_mask_dir, transform = val_transform)\n",
        "    val_loader = DataLoader(val_data, batch_size=batch_size, num_workers=num_workers, pin_memory=pin_memory, shuffle=False)\n",
        "\n",
        "    return train_loader, val_loader\n",
        "\n",
        "def check_accuracy(loader, model, device=\"cuda\"):\n",
        "    num_correct = 0 #did i predict correctly\n",
        "    num_pixels = 0 #how many pixel are correct Area accuracy\n",
        "\n",
        "    #In order to force the algorithm on finding a good solution instead of only putting black pixel to get a good accuracy due to the small size of the target\n",
        "    dice_score = 0\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for x, y in loader:\n",
        "            x = x.to(device)\n",
        "            y = y.to(device)\n",
        "\n",
        "            preds = torch.sigmoid(model(x))\n",
        "            preds = (preds > 0.5).float()\n",
        "\n",
        "            num_correct += (preds == y).sum()\n",
        "            num_pixels += torch.numel(preds)\n",
        "            dice_score += (2 * (preds * y).sum()) / ((preds + y).sum() + 1e-8) #calculate the intersection between ground truth and prediction\n",
        "\n",
        "    print(f\"Got {num_correct}/{num_pixels} with accuracy {num_correct/num_pixels*100}:.2f\")\n",
        "    print(f\"Dice score {dice_score/len(loader)}\")\n",
        "\n",
        "    model.train()\n",
        "\n",
        "def save_predictions_as_imgs(loader, model, folder = SAVE_DIR, device=\"cuda\"):\n",
        "    if not os.path.exists(folder):\n",
        "      os.mkdir(folder)\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    for i , (x, y) in enumerate(loader):\n",
        "        x = x.to(device)\n",
        "        with torch.no_grad():\n",
        "            preds = torch.sigmoid(model(x))\n",
        "            preds = (preds > 0.5).float()\n",
        "            #print(y.shape)\n",
        "            #print(preds.shape)\n",
        "            #y = (y > 0.5).float()\n",
        "\n",
        "            # preds_path = os.path.join(folder, f\"pred_{i}.jpg\")\n",
        "            # truth_path = os.path.join(folder, f\"truth_{i}.jpg\")\n",
        "            # print(preds_path)\n",
        "            # print(truth_path)\n",
        "\n",
        "\n",
        "            #cv2.imwrite(preds_path, preds.cpu().detach().numpy())\n",
        "            #cv2.imwrite(truth_path, y.cpu().detach().numpy())\n",
        "            torchvision.utils.save_image(preds, f\"{folder}/pred_{i}.jpg\")\n",
        "            torchvision.utils.save_image(y, f\"{folder}/truth_{i}.jpg\")"
      ],
      "metadata": {
        "id": "qaxrihkB8v7g"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(loader, model, optimizer, loss_fn, scaler):\n",
        "    loop = tqdm(loader)\n",
        "\n",
        "    for i_batch, (data, targets) in enumerate(loop):\n",
        "        data = data.to(device=DEVICE)\n",
        "        targets = targets.float().unsqueeze(1).to(device=DEVICE)\n",
        "\n",
        "        with torch.cuda.amp.autocast():\n",
        "            preds = model(data)\n",
        "            loss = loss_fn(preds, targets)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        scaler.scale(loss).backward()\n",
        "        scaler.step(optimizer)\n",
        "        scaler.update()\n",
        "\n",
        "        loop.set_postfix(loss=loss.item())"
      ],
      "metadata": {
        "id": "3WXnQTla67Qm"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn.functional as F"
      ],
      "metadata": {
        "id": "MQwP6_ZrZIQj"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DiceLoss(nn.Module):\n",
        "    def __init__(self, weight=None, size_average=True):\n",
        "        super(DiceLoss, self).__init__()\n",
        "\n",
        "    def forward(self, inputs, targets, smooth=1):\n",
        "\n",
        "        #comment out if your model contains a sigmoid or equivalent activation layer\n",
        "        inputs = F.sigmoid(inputs)\n",
        "\n",
        "        #flatten label and prediction tensors\n",
        "        inputs = inputs.view(-1)\n",
        "        targets = targets.view(-1)\n",
        "\n",
        "        intersection = (inputs * targets).sum()\n",
        "        dice = (2.*intersection + smooth)/(inputs.sum() + targets.sum() + smooth)\n",
        "\n",
        "        return 1. - dice"
      ],
      "metadata": {
        "id": "7trSmNcxYuZc"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6ptIJu4rZDuz"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_transform = transforms.Compose(\n",
        "    [\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Resize((IMAGE_HEIGHT, IMAGE_WIDTH)),\n",
        "        #A.Rotate(limit=35, p=1.0),\n",
        "        #A.HorizontalFlip(p=0.5),\n",
        "        #A.VerticalFlip(p=0.1),\n",
        "        #transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),\n",
        "        #transforms.Grayscale(),\n",
        "    ]\n",
        ")\n",
        "\n",
        "validation_transform = transforms.Compose(\n",
        "    [\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Resize((IMAGE_HEIGHT, IMAGE_WIDTH)),\n",
        "    ]\n",
        ")\n",
        "\n",
        "UNET = myUNET(in_channels=3, out_channels=1).to(DEVICE) #for multiple classes change out channels to number of classes\n",
        "#loss_fn = nn.BCEWithLogitsLoss() # for multiple classes use cross entropy\n",
        "\n",
        "loss_fn = DiceLoss() #Needed to force the NN to chose another strategy than putting every pixel to white\n",
        "optimizer = optim.Adam(UNET.parameters(), lr=LEARNING_RATE)\n",
        "\n",
        "train_loader, val_loader = get_loaders(\n",
        "    IMG_DIR_TRAIN,\n",
        "    MASK_DIR_TRAIN,\n",
        "    IMG_DIR_VAL,\n",
        "    MASK_DIR_VAL,\n",
        "    BATCH_SIZE,\n",
        "    train_transform,\n",
        "    validation_transform,\n",
        "    NUM_WORKERS,\n",
        "    PIN_MEMORY\n",
        ")\n",
        "\n",
        "scaler = torch.cuda.amp.GradScaler()\n",
        "\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "    #print(train_loader)\n",
        "    train(train_loader, UNET, optimizer, loss_fn, scaler)\n",
        "\n",
        "    checkpoint =  {\n",
        "        \"state_dict\": UNET.state_dict(),\n",
        "        \"optimizer\": optimizer.state_dict()\n",
        "    }\n",
        "\n",
        "    save_checkpoint(checkpoint)\n",
        "\n",
        "    check_accuracy(val_loader, UNET, device=DEVICE)\n",
        "\n",
        "    save_predictions_as_imgs(val_loader, UNET, folder=\"/content/Saved_Images\", device=DEVICE)"
      ],
      "metadata": {
        "id": "DAAUW9kb9YqE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "df275ac6-06a6-4b2e-8350-4dcd7c2b9859"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/50 [00:00<?, ?it/s]/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "100%|██████████| 50/50 [00:14<00:00,  3.36it/s, loss=0.981]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=> Saving checkpoint\n",
            "Got 7601927/7760800 with accuracy 97.95287322998047:.2f\n",
            "Dice score 0.21751512587070465\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 50/50 [00:11<00:00,  4.33it/s, loss=0.243]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=> Saving checkpoint\n",
            "Got 7747275/7760800 with accuracy 99.82572174072266:.2f\n",
            "Dice score 0.7050676345825195\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 50/50 [00:11<00:00,  4.27it/s, loss=0.274]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=> Saving checkpoint\n",
            "Got 7748374/7760800 with accuracy 99.83988189697266:.2f\n",
            "Dice score 0.7184677124023438\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 50/50 [00:11<00:00,  4.29it/s, loss=0.212]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=> Saving checkpoint\n",
            "Got 7747928/7760800 with accuracy 99.83413696289062:.2f\n",
            "Dice score 0.7356622219085693\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 50/50 [00:11<00:00,  4.33it/s, loss=0.307]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=> Saving checkpoint\n",
            "Got 7749071/7760800 with accuracy 99.84886932373047:.2f\n",
            "Dice score 0.749110758304596\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 50/50 [00:11<00:00,  4.33it/s, loss=0.217]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=> Saving checkpoint\n",
            "Got 7751285/7760800 with accuracy 99.87739562988281:.2f\n",
            "Dice score 0.7884252667427063\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 50/50 [00:11<00:00,  4.34it/s, loss=0.21]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=> Saving checkpoint\n",
            "Got 7751366/7760800 with accuracy 99.87843322753906:.2f\n",
            "Dice score 0.7893178462982178\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 50/50 [00:11<00:00,  4.31it/s, loss=0.234]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=> Saving checkpoint\n",
            "Got 7752142/7760800 with accuracy 99.88843536376953:.2f\n",
            "Dice score 0.805050790309906\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 50/50 [00:11<00:00,  4.33it/s, loss=0.251]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=> Saving checkpoint\n",
            "Got 7752067/7760800 with accuracy 99.88746643066406:.2f\n",
            "Dice score 0.8080037236213684\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 50/50 [00:11<00:00,  4.32it/s, loss=0.174]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=> Saving checkpoint\n",
            "Got 7752919/7760800 with accuracy 99.89844512939453:.2f\n",
            "Dice score 0.8266234993934631\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 50/50 [00:11<00:00,  4.34it/s, loss=0.245]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=> Saving checkpoint\n",
            "Got 7752994/7760800 with accuracy 99.8994140625:.2f\n",
            "Dice score 0.827548086643219\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 50/50 [00:11<00:00,  4.31it/s, loss=0.214]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=> Saving checkpoint\n",
            "Got 7752542/7760800 with accuracy 99.89358520507812:.2f\n",
            "Dice score 0.8235488533973694\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 50/50 [00:11<00:00,  4.32it/s, loss=0.165]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=> Saving checkpoint\n",
            "Got 7753249/7760800 with accuracy 99.90270233154297:.2f\n",
            "Dice score 0.8355377316474915\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 50/50 [00:11<00:00,  4.30it/s, loss=0.155]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=> Saving checkpoint\n",
            "Got 7753524/7760800 with accuracy 99.90624237060547:.2f\n",
            "Dice score 0.836152195930481\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 50/50 [00:11<00:00,  4.34it/s, loss=0.164]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=> Saving checkpoint\n",
            "Got 7753327/7760800 with accuracy 99.90370178222656:.2f\n",
            "Dice score 0.8373703956604004\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 50/50 [00:11<00:00,  4.33it/s, loss=0.157]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=> Saving checkpoint\n",
            "Got 7753829/7760800 with accuracy 99.91017150878906:.2f\n",
            "Dice score 0.8441529273986816\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 50/50 [00:11<00:00,  4.32it/s, loss=0.189]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=> Saving checkpoint\n",
            "Got 7753390/7760800 with accuracy 99.90451049804688:.2f\n",
            "Dice score 0.8255047798156738\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 50/50 [00:11<00:00,  4.33it/s, loss=0.137]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=> Saving checkpoint\n",
            "Got 7753506/7760800 with accuracy 99.906005859375:.2f\n",
            "Dice score 0.8338244557380676\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 50/50 [00:11<00:00,  4.35it/s, loss=0.0942]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=> Saving checkpoint\n",
            "Got 7753277/7760800 with accuracy 99.90306091308594:.2f\n",
            "Dice score 0.8437698483467102\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 50/50 [00:11<00:00,  4.32it/s, loss=0.121]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=> Saving checkpoint\n",
            "Got 7753314/7760800 with accuracy 99.90353393554688:.2f\n",
            "Dice score 0.8432862758636475\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 50/50 [00:11<00:00,  4.34it/s, loss=0.0987]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=> Saving checkpoint\n",
            "Got 7753815/7760800 with accuracy 99.90998840332031:.2f\n",
            "Dice score 0.8453930616378784\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 50/50 [00:11<00:00,  4.33it/s, loss=0.114]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=> Saving checkpoint\n",
            "Got 7753917/7760800 with accuracy 99.91130828857422:.2f\n",
            "Dice score 0.8428203463554382\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 50/50 [00:11<00:00,  4.32it/s, loss=0.125]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=> Saving checkpoint\n",
            "Got 7753152/7760800 with accuracy 99.90145111083984:.2f\n",
            "Dice score 0.8331891298294067\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 50/50 [00:11<00:00,  4.36it/s, loss=0.124]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=> Saving checkpoint\n",
            "Got 7753805/7760800 with accuracy 99.90986633300781:.2f\n",
            "Dice score 0.8373802900314331\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 50/50 [00:11<00:00,  4.34it/s, loss=0.146]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=> Saving checkpoint\n",
            "Got 7753546/7760800 with accuracy 99.90652465820312:.2f\n",
            "Dice score 0.8417098522186279\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 50/50 [00:11<00:00,  4.34it/s, loss=0.107]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=> Saving checkpoint\n",
            "Got 7753640/7760800 with accuracy 99.9077377319336:.2f\n",
            "Dice score 0.8368716239929199\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 50/50 [00:11<00:00,  4.27it/s, loss=0.0902]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=> Saving checkpoint\n",
            "Got 7754045/7760800 with accuracy 99.91295623779297:.2f\n",
            "Dice score 0.8460850119590759\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 50/50 [00:11<00:00,  4.34it/s, loss=0.0858]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=> Saving checkpoint\n",
            "Got 7753919/7760800 with accuracy 99.91133117675781:.2f\n",
            "Dice score 0.8448656797409058\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 50/50 [00:11<00:00,  4.33it/s, loss=0.133]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=> Saving checkpoint\n",
            "Got 7753334/7760800 with accuracy 99.90379333496094:.2f\n",
            "Dice score 0.845048189163208\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 50/50 [00:11<00:00,  4.36it/s, loss=0.0835]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=> Saving checkpoint\n",
            "Got 7753487/7760800 with accuracy 99.90576171875:.2f\n",
            "Dice score 0.8432580828666687\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "truth_image = Image.open('/content/Saved_Images/truth_0.jpg')\n",
        "pred_image = Image.open('/content/Saved_Images/pred_0.jpg')\n",
        "\n",
        "\n",
        "figure_size = 15\n",
        "plt.figure(figsize=(figure_size,figure_size))\n",
        "plt.subplot(1,2,1),plt.imshow(truth_image)\n",
        "plt.title('Truth Image'), plt.xticks([]), plt.yticks([])\n",
        "plt.subplot(1,2,2),plt.imshow(pred_image)\n",
        "plt.title('Prediction Image'), plt.xticks([]), plt.yticks([])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "uHjPc3IaE66I",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "0962c2dd-fd8b-4685-966e-e3b0d74e6e6c"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1500x1500 with 2 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAABJ4AAADMCAYAAAAyGmkFAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAxJUlEQVR4nO3deXgUVbrH8V/1kn0hkIQlYUcWARcYxcgqIFGIXFQ2GRQZ5aIoyLiNOuMAIw+4XBW3CwEREXEZ9I7LHUVBQQUVHUCQVXYREMKSBAhZOn3uH97qSQhLd6RIGr+f56nnSSp1qk9VnTr19ltVJ5YxxggAAAAAAAA4w1xVXQEAAAAAAACcm0g8AQAAAAAAwBEkngAAAAAAAOAIEk8AAAAAAABwBIknAAAAAAAAOILEEwAAAAAAABxB4gkAAAAAAACOIPEEAAAAAAAAR5B4AgAAAAAAgCNIPAFQo0aNlJWVVdXVAAAA+M1r1KiRbr755sDvixcvlmVZWrx48Rn7DMuyNH78+DO2PgA4FRJPQBWzLCuo6dcGG+vWrdP48eO1ffv2M1LvsizL0p133nnG1wsAAHA2vfzyy+Xir6ioKDVv3lx33nmn9u7dW9XVC8kHH3xQ7ZJL48ePl2VZ2r9/f1VXBcBZ5KnqCgC/dXPmzCn3+yuvvKIFCxZUmN+qVatf9Tnr1q3ThAkT1K1bNzVq1OhXrQsAAOBc9re//U2NGzdWYWGhlixZoqlTp+qDDz7QmjVrFBMTc1br0qVLFx07dkwREREhlfvggw/0wgsvnDD5dOzYMXk8fBUEcHbQ2wBVbOjQoeV+//rrr7VgwYIK849XUFBw1gMfAACA34Krr75av/vd7yRJt956q2rVqqWnnnpK7777rm644YYTljl69KhiY2PPeF1cLpeioqLO6DrP9PoA4FR41Q4IA926dVObNm20fPlydenSRTExMXrooYcknfwd/bLjA7z88ssaMGCAJOmKK6446et7S5Ys0aWXXqqoqCg1adJEr7zySqXqa49F8Pe//10TJkxQWlqa4uPj1b9/f+Xl5amoqEhjx45Vamqq4uLiNHz4cBUVFZVbx6xZs9S9e3elpqYqMjJS559/vqZOnVrhs/x+v8aPH6969eopJiZGV1xxhdatW1dhfARJys3N1dixY1W/fn1FRkaqWbNmeuyxx+T3+yu1nQAA4Lehe/fukqRt27ZJkm6++WbFxcVpy5Yt6t27t+Lj4/X73/9e0i+xyZQpU9S6dWtFRUWpdu3aGjlypA4dOlRuncYYTZw4Uenp6YEYZu3atRU++2RjPC1btky9e/dWUlKSYmNjdcEFF+iZZ54J1O+FF16QVH5YB9uJ4seVK1fq6quvVkJCguLi4tSjRw99/fXX5ZaxX0VcunSp7r77bqWkpCg2NlbXXnutcnJyQtyrv7Dj3NWrV6tr166KiYlRs2bN9NZbb0mSPvvsM3Xo0EHR0dFq0aKFFi5cWK78jh07NGrUKLVo0ULR0dGqVauWBgwYcMLhJezPiI6OVnp6uiZOnKhZs2bJsqwKy3/44Yfq3LmzYmNjFR8frz59+pzw+AA4PZ54AsLEgQMHdPXVV2vw4MEaOnSoateuHXTZLl26aMyYMXr22Wf10EMPBV7bK/v63ubNm9W/f3/dcsstGjZsmF566SXdfPPNat++vVq3bl2pOk+ePFnR0dF64IEHtHnzZj333HPyer1yuVw6dOiQxo8fr6+//lovv/yyGjdurL/+9a+BslOnTlXr1q3Vt29feTwevf/++xo1apT8fr/uuOOOwHIPPvigHn/8cV1zzTXKzMzUqlWrlJmZqcLCwnJ1KSgoUNeuXbVr1y6NHDlSDRo00JdffqkHH3xQe/bs0ZQpUyq1jQAA4Ny3ZcsWSVKtWrUC83w+nzIzM9WpUyf913/9V+BJ9JEjR+rll1/W8OHDNWbMGG3btk3PP/+8Vq5cqaVLl8rr9UqS/vrXv2rixInq3bu3evfurRUrVqhXr14qLi4+bX0WLFigrKws1a1bV3fddZfq1Kmj9evX63//93911113aeTIkdq9e/cJh284kbVr16pz585KSEjQ/fffL6/Xq+zsbHXr1i2Q+Clr9OjRSkpK0rhx47R9+3ZNmTJFd955p958882g92lZhw4dUlZWlgYPHqwBAwZo6tSpGjx4sObOnauxY8fqtttu05AhQ/TEE0+of//+2rlzp+Lj4yVJ3377rb788ksNHjxY6enp2r59u6ZOnapu3bpp3bp1geOya9euwA3YBx98ULGxsXrxxRcVGRlZoT5z5szRsGHDlJmZqccee0wFBQWaOnWqOnXqpJUrVzJsBRAqA6BaueOOO8zxp2bXrl2NJDNt2rQKy0sy48aNqzC/YcOGZtiwYYHf582bZySZRYsWnXBZSebzzz8PzNu3b5+JjIw099xzz2nrLMnccccdgd8XLVpkJJk2bdqY4uLiwPwbbrjBWJZlrr766nLlMzIyTMOGDcvNKygoqPA5mZmZpkmTJoHff/75Z+PxeEy/fv3KLTd+/Hgjqdz2P/LIIyY2Ntb88MMP5ZZ94IEHjNvtNj/++ONptxMAAJzbZs2aZSSZhQsXmpycHLNz507zxhtvmFq1apno6Gjz008/GWOMGTZsmJFkHnjggXLlv/jiCyPJzJ07t9z8+fPnl5u/b98+ExERYfr06WP8fn9guYceeqhCDGPHVXYM5/P5TOPGjU3Dhg3NoUOHyn1O2XWdKKa0HR8/9uvXz0RERJgtW7YE5u3evdvEx8ebLl26VNg/PXv2LPdZf/zjH43b7Ta5ubkn/DzbuHHjjCSTk5MTmGfHua+99lpg3oYNG4wk43K5zNdffx2Y/9FHHxlJZtasWYF5J4oZv/rqKyPJvPLKK4F5o0ePNpZlmZUrVwbmHThwwNSsWdNIMtu2bTPGGHP48GFTo0YNM2LEiHLr/Pnnn01iYmKF+QBOj1ftgDARGRmp4cOHO7b+888/X507dw78npKSohYtWmjr1q2VXudNN90UuKsnSR06dJAxRn/4wx/KLdehQwft3LlTPp8vMC86Ojrwc15envbv36+uXbtq69atysvLkyR98skn8vl8GjVqVLn1jR49ukJd5s2bp86dOyspKUn79+8PTD179lRpaak+//zzSm8nAAA4t/Ts2VMpKSmqX7++Bg8erLi4OP3jH/9QWlpaueVuv/32cr/PmzdPiYmJuvLKK8vFG+3bt1dcXJwWLVokSVq4cKGKi4s1evTocq/AjR079rR1W7lypbZt26axY8eqRo0a5f5Wdl3BKi0t1ccff6x+/fqpSZMmgfl169bVkCFDtGTJEuXn55cr85//+Z/lPqtz584qLS3Vjh07Qv58SYqLi9PgwYMDv7do0UI1atRQq1atyj1tZf9cNj4tGzOWlJTowIEDatasmWrUqKEVK1YE/jZ//nxlZGTooosuCsyrWbNm4BVJ24IFC5Sbm6sbbrih3DF0u93q0KFD4BgCCB6v2gFhIi0tLeT/ZhKKBg0aVJiXlJRUYTyCX7POxMRESVL9+vUrzPf7/crLyws8wr506VKNGzdOX331lQoKCsotn5eXp8TExEBw06xZs3J/r1mzppKSksrN27Rpk1avXq2UlJQT1nXfvn0hbh0AADhXvfDCC2revLk8Ho9q166tFi1ayOUqf8/e4/EoPT293LxNmzYpLy9PqampJ1yvHW/YMcx5551X7u8pKSkVYpjj2a/9tWnTJvgNOoWcnBwVFBSoRYsWFf7WqlUr+f1+7dy5s9zQC8fHeHadKxs3pqenV0iaJSYmnjBmPP5zjh07psmTJ2vWrFnatWuXjDGBv9k3K6Vf9nlGRkaFzz4+jty0aZOkf4/rdbyEhIRgNglAGSSegDBR9m5OMEpLS0Na3u12n3B+2Yt3qE62ztN91pYtW9SjRw+1bNlSTz31lOrXr6+IiAh98MEHevrppys1GLjf79eVV16p+++//4R/b968ecjrBAAA56ZLL7008F/tTiYyMrJCMsrv9ys1NVVz5849YZmT3QALN2c6bqxszCj98qT7rFmzNHbsWGVkZCgxMVGWZWnw4MGVjhmlX8Z5qlOnToW/ezx8hQZCxVkDhLmkpCTl5uaWm1dcXKw9e/aUm1eZR6+ryvvvv6+ioiK999575e6oHf9oc8OGDSX9MjB648aNA/MPHDhQ4Y5b06ZNdeTIEfXs2dPBmgMAgN+ypk2bauHCherYseMpbxraMcymTZvKvd6Wk5Nz2qeGmjZtKklas2bNKeOaYGO/lJQUxcTEaOPGjRX+tmHDBrlcrgpPHlUnb731loYNG6Ynn3wyMK+wsLBCfNywYUNt3ry5Qvnj59n7NzU1lbgROEMY4wkIc02bNq0wPtH06dMrPPEUGxsrSRUuwtWRfXfr+EelZ82aVW65Hj16yOPxaOrUqeXmP//88xXWOXDgQH311Vf66KOPKvwtNze33PhSAAAAlTFw4ECVlpbqkUceqfA3n88XiMN69uwpr9er5557rly8E8x/2W3Xrp0aN26sKVOmVIjryq4r2NjP7XarV69eevfdd7V9+/bA/L179+q1115Tp06dqvXrZW63u8KTVs8991yFWDgzM1NfffWVvvvuu8C8gwcPVng6LTMzUwkJCZo0aZJKSkoqfF5OTs6ZqzzwG8ETT0CYu/XWW3Xbbbfp+uuv15VXXqlVq1bpo48+UnJycrnlLrroIrndbj322GPKy8tTZGSkunfvftIxCKpSr169FBERoWuuuUYjR47UkSNHNGPGDKWmppZ7kqt27dq666679OSTT6pv37666qqrtGrVKn344YdKTk4ud6fvvvvu03vvvaesrCzdfPPNat++vY4eParvv/9eb731lrZv315hnwEAAISia9euGjlypCZPnqzvvvtOvXr1ktfr1aZNmzRv3jw988wz6t+/v1JSUnTvvfdq8uTJysrKUu/evbVy5cpADHMqLpdLU6dO1TXXXKOLLrpIw4cPV926dbVhwwatXbs2cJOtffv2kqQxY8YoMzNTbre73ADeZU2cOFELFixQp06dNGrUKHk8HmVnZ6uoqEiPP/74md1JZ1hWVpbmzJmjxMREnX/++frqq6+0cOHCwLihtvvvv1+vvvqqrrzySo0ePVqxsbF68cUX1aBBAx08eDAQNyYkJGjq1Km68cYb1a5dOw0ePFgpKSn68ccf9c9//lMdO3Y84U1OACdH4gkIcyNGjNC2bds0c+ZMzZ8/X507d9aCBQvUo0ePcsvVqVNH06ZN0+TJk3XLLbeotLRUixYtqpaJpxYtWuitt97SX/7yF917772qU6eObr/9dqWkpFT4j3iPPfaYYmJiNGPGDC1cuFAZGRn6+OOP1alTJ0VFRQWWi4mJ0WeffaZJkyZp3rx5euWVV5SQkKDmzZtrwoQJgcEqAQAAfo1p06apffv2ys7O1kMPPSSPx6NGjRpp6NCh6tixY2C5iRMnKioqStOmTdOiRYvUoUMHffzxx+rTp89pPyMzM1OLFi3ShAkT9OSTT8rv96tp06YaMWJEYJnrrrtOo0eP1htvvKFXX31VxpiTJp5at26tL774Qg8++KAmT54sv9+vDh066NVXXy33X+Wqo2eeeUZut1tz585VYWGhOnbsqIULFyozM7PccvXr19eiRYs0ZswYTZo0SSkpKbrjjjsUGxurMWPGlIsbhwwZonr16unRRx/VE088oaKiIqWlpalz586O/pdp4FxlmV8zcjAAVEO5ublKSkrSxIkT9ec//7mqqwMAAIBqauzYscrOztaRI0dOOpg5gF+HMZ4AhLVjx45VmGePj9CtW7ezWxkAAABUW8fHjQcOHNCcOXPUqVMnkk6Ag3jVDkBYe/PNN/Xyyy+rd+/eiouL05IlS/T666+rV69e5R5nBwAAwG9bRkaGunXrplatWmnv3r2aOXOm8vPz9fDDD1d11YBzGoknAGHtggsukMfj0eOPP678/PzAgOMTJ06s6qoBAACgGundu7feeustTZ8+XZZlqV27dpo5c6a6dOlS1VUDzmmM8QQAAAAAAABHMMYTAAAAAAAAHEHiCQAAAAAAAI4Iaownv9+v3bt3Kz4+XpZlOV0nAABwDjDG6PDhw6pXr55cLu51VVfEeQAAIFShxHlBJZ52796t+vXrn5HKAQCA35adO3cqPT29qquBkyDOAwAAlRVMnBfU7cf4+PgzUiEAAPDbQxxRvXF8AABAZQUTRwSVeOKxawAAUFnEEdUbxwcAAFRWMHEEAy4AAAAAAADAESSeAAAAAAAA4AgSTwAAAAAAAHAEiScAAAAAAAA4gsQTAAAAAAAAHEHiCQAAAAAAAI4g8QQAAAAAAABHkHgCAAAAAACAI0g8AQAAAAAAwBEkngAAAAAAAOAIEk8AAAAAAABwBIknAAAAAAAAOILEEwAAAAAAABxB4gkAAAAAAACOIPEEAAAAAAAAR5B4AgAAAAAAgCNIPAEAAAAAAMARJJ4AAAAAAADgCBJPAAAAAAAAcASJJwAAAAAAADiCxBMAAAAAAAAcQeIJAAAAAAAAjiDxBAAAAAAAAEeQeAIAAAAAAIAjSDwBAAAAAADAESSeAAAAAAAA4AgSTwAAAAAAAHAEiScAAAAAAAA4gsQTAAAAAAAAHEHiCQAAAAAAAI4g8QQAAAAAAABHkHgCAAAAAACAI0g8AQAAAAAAwBEkngAAAAAAAOAIEk8AAAAAAABwhKeqK/Brud1uGWMCv1uWJWOM/H5/FdYqdC7XLzlAu/7GGLlcLpWWloa0HrfbLUkhl6tuPB6PjDHl9oc9nYplWeXahL2OcN4fZbfndO3asqzAVHb/BVO2OnO73XK5XPL7/eWO7enag/Tvcyuctx/l2edEkyZNdPDgQeXm5p60PViWJZfLFehPK9u3novs64Wt7PkFnGmVjU9cLle5a5qksIzz7Guz3f/YvwezP+zrmMvlCikmqq7sPtnv95c7pr/VOM/eB2WP76muU2Xbg31u2Ne3cGVvi2VZgXO7Mu3Bnufz+Ryt75lm94/2eSGF3s+V/Q4Qztdzu5+MjIxUz549lZubq6VLlwa1TWX72XBrAydjnxtS6NdPj8dTrp+t6nYR9k88WZal9u3ba9SoUcrIyCh3cMKJfeG0O9DjO9FglL1wheM+sLlcLsXExCg9PV0JCQmSfjlxgtkmj+eXXKq9P+2ERTgr2zaCWdblcsnj8SgrK0sZGRnlkk/hyN72hIQE1atXT9HR0UEf07IXoHA+J/Bv9jG94oor9MUXX2jOnDlKSEg46fG1j32tWrVUr149RURE0Bb+X4cOHTRy5Ehdeuml5QJW4Eyz+2H751DFxsYqPT1dtWvXrpAwDRf2PoiLi1OfPn3UuHHjkPaFXf5ciWtq1qxJnFdG2eN7uu8A9rItW7bUiBEj1L1797DfB5ZlKSIiQomJiXK73UGfG5ZlKTo6WmlpaapZs6YkhWXMa7fnZs2a6fe//72ioqIqvY6ySfpwZJ/XjzzyiN544w3NmTNHTZo0CWmbwn0flGW358psT2pqqtLS0pSSklI94jwThLy8PCPJ0SkiIsIkJiaaiIiIkMo1aNDAbNmyxZSUlJhdu3aZ5s2bG7fb7Xh9z/TkdruN2+02F198sZk9e7a57LLLQt6O2NhY06dPH5OcnGwsy6rybarsFBcXZ1577TVz4MABs3DhQlO3bl3jcrmCKuv1es2QIUPM//zP/5iHHnrIxMbGhvW+kGRcLpdJTk42ffr0MTExMadc1rIs43a7Te/evU1+fr7ZtWuXadGiRVjvA8uyTMOGDc3SpUvN/v37TXZ2dtDH1eVymX79+pkXX3zRpKWlVfm2MJ2Zyev1muHDh5ujR4+atWvXnrKPcLlc5rLLLjMbN240+/btM/fcc0/I15nqPLlcLhMfHx/yOd6gQQOzfft2U1RUZHbs2GGaNm1qPB6PY9fPvLy8YMINVBGn4zyXy2VSU1NNnz59TK1atUI+32fOnGn2799vNm/ebNq2bWu8Xm+Vn3uhTm6323i9XvPiiy+aI0eOmK1bt5rWrVuftpxlWcbj8RiXy2V69OhhZs+ebQYOHBjW/VhsbKz55JNPTE5OTshxXkRExDkZ53m9XtO3b9+gvgN4PB6TnJxsVqxYYYqLi82OHTtM48aNq3w7KjtZlmUaNGhg3n33XbNy5UrTv3//QJs/XdmoqCjzwgsvmJycHLNs2TLTpEmTsPwe6HK5jNvtNtnZ2aawsNDcd999QZ8TZadatWqZq6++2sTHx1f5Nv2a9hAdHW2WL19uSkpKTEFBgenfv/9p94dlWaZLly5mypQp5pJLLgn7fsGevF6vSU1NNc2aNQupTTRo0MBs2rTJ5OTkmI0bN1aLOK9aJJ7i4uLMzJkzzbZt28yLL75o4uPjg96xLVq0MPn5+aakpMQcPXrUtG/fPmwDEo/HY959911TVFRkPv30UxMVFRV0WbfbbR599FFz9OhRM2fOnLDcB/bUuHFjc+jQIVNSUmKKiopMx44dgz5J0tLSzO7du01xcbE5duxYSGWr6xQZGWnmzp1rioqKzKRJk4zH4zllZ+p2u027du3Mli1bzJdffhlSQFcdJ8uyTFZWlikpKTE+n8/8/PPPpm7dukFdUGrWrGl++OEH4/P5zOOPP27cbndY7gs7IKldu7aZNGmSycjIqNQFNT4+3vz5z382ffr0MW6321iWFXYXZvtLWGRkpBk0aJBp165dYFtOtu/+8pe/BNrPN998E9Zf2I7fF3/4wx/M+vXrTf/+/UMqe/7555u8vDxTUlJijhw5Yi688MJT7sdfO5F4qt6cjvMSEhLMokWLTFFRkVm+fLlJS0sLui9OT083O3bsMD6fzxQXF5uxY8caj8dT5edfqJMd5y1YsMCUlJSYwsJC07dv36DKer1eU7t2bbNu3TpTVFRkjhw5Yn73u99V+TZVdvo1cV56err56aefAnFely5dwvK6fnzbOO+888zBgweNz+czixcvPmUc7/F4THx8vFm4cKEpLi42u3fvNuedd16Vb0dlJ8uyTJ8+fUxJSYkpKSkx27dvN6mpqUFdj1JSUsxPP/1kfD6f8fl85vrrrw/L/sG+cXzjjTearVu3mr/+9a8ht2uPx2Nmz55tCgsLzaRJk6p8myo72THvNddcYz799FMzZ84ck5SUdMr24HK5TO3atc2OHTtMcXGx+eGHH0ydOnWqfFvOxNSvXz+zbds2s2fPnkACLpi20apVq2oX51WL5zKbNGmiQYMGKS0tTQMHDlSjRo2CfjXmp59+UnZ2tn744QfNnj1bGzduDNtHLCVpxowZWr16taZOnRr0e5zm/x8nPHLkiCSpoKAgLPeBLTc3V2vWrJExRlu2bNGuXbvKPaZ/Kn6/XyUlJZIkn88XePUs3B09elQ+ny/oY7t69Wr16NFD1157rXJycs5CDZ1jWZZ27NihXbt2qbS0VN99950KCgqC6h+OHDmi6dOn65tvvtHf//73wPrCjX2OP/DAA7r33ns1bdo0xcfHh7yem266SePGjVN2drbS09PDdl/4/X75fD794x//0KpVq045DoRlWVq9erUOHz4sn8+nZcuWBeaHO5fLpRtuuEFNmjTRwIEDQyq7detWvfTSS/rhhx/00ksvaevWrefUo+moXho2bKhLL71UktSqVSslJSUF3dZ+/vlnzZ07VyUlJdqzZ48+/fRTJ6vqGLuPeuaZZ/T9999r2bJlWr16ddBlS0tL5fP5wnYs07J+TZxXWloa2HZ7vJJzod86fPiwNm/eHIhjT7VNxhgVFBRoxIgRevjhhzV27Fht3br1LNb2zFu+fLmWL18un8+nzz//XHl5eUGVO3bsmFauXKnS0lLt3r1b27Ztc7imzrBfsXz99dfVuXNnPf300yG/VmxZlho1aiSPx6MLLrjAoZo6zz6/58+fr8zMTN16663Kz88/6fJlX+O2xzqrUaNG4NXLcNe0aVOlpaWpVq1aOu+884Lu77Zt21b94rzqcCesfv36ZtOmTaakpMSsX7/eNGzY8LRPddiT2+02UVFRJi4uzni93qCzgNVtsp9aioiIMNHR0cbj8QT91JKdJY+LizOXX365SUxMDMt9UHZ70tPTzRVXXGGaNm0aUnbW5XKZrKwsM336dHPbbbeZiIiIsLzzcfw2JSQkmIyMDBMTE2Msyzrp8bWfBrHbk30+hHN7cLlcxuPxmNatW5srrrjC1K5dO+gnlyzLMl6v18TExAT2Q7g94WNvh/2axfr1683DDz9sIiMjQ17HhRdeaFasWGGys7NNXFxc2O4P+1ja7fxUT27Zr7dccsklpkuXLiY+Pt7ROz5ne2rbtq2ZMmVKpe52e71eExsbayIiIhw/P3jiqXo7G3Hexo0bjc/nMxs2bDD169cP+rpkWZaJjY0tFxOE4zWtbJwXExNjYmJignrKx+7/3W636du3r5kxY4a55ZZbwjq2+bVxXp8+fcz7779vHn30URMbGxuW7eH4tuHxeEzDhg0D++RUx7fsNdD+vhDO1zT7e0xKSorp1q1bIM4LZpssyzLJycmma9eu5vzzzzderzcs33Sw+we7f7OPbaj78aKLLjLz5s0z9957b5Vv06+Z7DZuf6c51XcZu4/0er3mqquuMjNmzDCjRo0Ky3Zwoql169Zm5syZ5u233zYXXHBB4HwJpmx1i/MsY07/+ER+fr4SExNPt1ilud1utW3bVq1atdLq1au1du1axz4LAMJZYmJi4Am4yoiPj1dRUZGKi4vPcM2Ak8vLywsMIozqhzgP4SYiIoLrGHACXq838NYHzg2WZcnj8QTe6qmOgonzqkXiqexrdVX9b/4AAMCZReKpeiPOAwAAlRVMnFctBr8xpxifAwAAAOGLOA8AgN82T1VXQCIgAQAAOFcR5wEA8NtWLZ54AgAAAAAAwLmHxBMAAAAAAAAcQeIJAAAAAAAAjiDxBAAAAAAAAEeQeAIAAAAAAIAjSDwBAAAAAADAESSeAAAAAAAA4AgSTwAAAAAAAHAEiScAAAAAAAA4gsQTAAAAAAAAHEHiCQAAAAAAAI4g8QQAAAAAAABHkHgCAAAAAACAI0g8AQAAAAAAwBEkngAAAAAAAOAIEk8AAAAAAABwBIknAAAAAAAAOILEEwAAAAAAABxB4gkAAAAAAACOIPEEAAAAAAAAR5B4AgAAAAAAgCNIPAEAAAAAAMARJJ4AAAAAAADgCBJPAAAAAAAAcASJJwAAAAAAADiCxBMAAAAAAAAcQeIJAAAAAAAAjiDxBAAAAAAAAEeQeAIAAAAAAIAjSDwBAAAAAADAESSeAAAAAAAA4AgSTwAAAAAAAHAEiScAAAAAAAA4gsQTAAAAAAAAHEHiCQAAAAAAAI4g8QQAAAAAAABHkHgCAAAAAACAI0g8AQAAAAAAwBEkngAAAAAAAOAIEk8AAAAAAABwBIknAAAAAAAAOILEEwAAAAAAABxB4gkAAAAAAACOIPEEAAAAAAAAR5B4AgAAAAAAgCNIPAEAAAAAAMARJJ4AAAAAAADgCBJPAAAAAAAAcASJJwAAAAAAADiCxBMAAAAAAAAcQeIJAAAAAAAAjiDxBAAAAAAAAEeQeAIAAAAAAIAjSDwBAAAAAADAESSeAAAAAAAA4AgSTwAAAAAAAHAEiScAAAAAAAA4gsQTAAAAAAAAHEHiCQAAAAAAAI4g8QQAAAAAAABHkHgCAAAAAACAI0g8AQAAAAAAwBEkngAAAAAAAOAIEk8AAAAAAABwBIknAAAAAAAAOILEEwAAAAAAABxB4gkAAAAAAACOIPEEAAAAAAAAR5B4AgAAAAAAgCNIPAEAAAAAAMARJJ4AAAAAAADgCBJPAAAAAIAqZVlWpcpUphyAs8tT1RWQJJfLJcuylJycLK/Xq5ycHPl8Pvn9fhljTlnW7myioqKUkJCgffv2SZL8fv/ZqLoj3G63jDGBbbO35XTbZFmWatWqpaioKO3fv1/FxcWSJGPMafdjdWJvd2RkpGrUqKG9e/dKCu6Y2mUjIiJUs2ZN7d27V8aYsGsP9jkRHR2tGjVqKD8/X4cPHw7pOFqWpaSkJMXExOjAgQMqKiqSFN7toV+/flq1apU2btwYVP/gdrvVq1cvHTlyRF988cVZqrEz7DaRmpoqy7K0b98++Xy+oMtJUnJystxut3JyclRSUuJ0lR3TtGlTXXnlldqxY4cWLlwov98f9PWiYcOGyszM1K5duzR//nwZY1RaWnqWan5mlA2wy14ngj2vXS6XPB6PUlNTVVhYqIMHD4ZdH4nwYlmWXC6XXC6XUlJSVFhYqLy8vJCvz5dffrkuvPBCLV68WOvXr3ewxs5yuVyKjIyU3+9XaWlp0HGey+VS27Ztddlll2np0qWBfRDK+V8dlE0U+P1+uVyuwM/B8Hg8at68uUpLS7V58+awj/OSkpK0d+9elZaWhnw9suPEnJycwD4ItzhP+uWYJicn609/+pMOHDig//7v/9ahQ4dOux01atTQ448/rjp16mjKlCn67LPPJCnsrusScV5ZMTExuu666+T1evXOO+8oPz8/qH7O7luTk5Pl9/u1b9++oGPE6sruH6Xg+ki7PRhjlJKSotLSUh06dKh6nBMmCHl5eUaSY5PL5TIXXnihWbNmjdm3b58ZP368iYiIMC6X67RlPR6PiYmJMdOnTzfbtm0z3bt3N26329H6Oj01a9bMvPLKK2b27NmmWbNmxuPxBLUvmjRpYv71r3+ZnJwc8+STT5ro6GjjcrmMZVlVvk2htofo6GjzwgsvmB07dphevXoZj8cT1Ha43W4TFRVlnnzySfPjjz+avn37hmV7cLvdJiEhwcyePdvs37/fLFq0yNSrVy+kdaSlpZklS5aYnJwck52dbeLi4sKyPbjdbuN2u80f//hHU1hYaJYvX25q1qwZ1HZ0797dHDhwwOzZs8e0bNmyyrfl1+6Dvn37mp07d5pdu3aZQYMGBVXW5XIZt9ttrrrqKrNt2zazZ88ec9NNN1X5NlV2io2NNUuXLjXFxcXm0KFDpnv37sbr9QbVHqKjo80nn3xiioqKTG5urundu7fxer1Vvk2hTi6XK9BPjh071jz66KMmMTExqLIej8d4vV4zbtw4k5OTY1avXm3atGnjeJ3z8vKCCTdQRZyO8yzLMl6v1wwdOtTs3r3bLF682NSrVy+o2MaeIiMjzWeffWYKCwvNt99+a2rUqFHl52Jlp379+pkPP/zQvP322yHFeS1btjQ7duwwRUVFZvv27aZZs2bG7XaH3XXdsiwTExNjHnnkETNv3jzz8MMPm6ioqKDKulwu07x5c7N161aza9eucybOmzBhgomJiQlpHWlpaebtt982O3fuNE888UTYxnn2/rjnnntMcXGxKSoqMtnZ2UFtR//+/U1RUZEpKioyX3/9tUlMTAzb9kCc98tkWZa5//77TUFBgSkqKjLPPvts0H2k2+02Y8aMMTk5OWbPnj1m5MiRQX+HrI6TZVnmjjvuMK+99ppp1apVSO2hS5cuZvPmzeb77783bdu2dbyuwcR51eJVO2OMunTpohYtWqhmzZoaOHCgvF5vUJlJY4zi4uLUuXNn1atXT5dccknYP275pz/9SYMGDdKQIUN03333BZ2hveSSS9S2bVslJCRowIABio6ODst9YYxRTEyMOnfurLp16+qyyy4LejuMMYqKilLXrl1Vp04dZWRkhOU+kKSaNWsqKytLiYmJuvzyy9W8efOQyrdp00aXXHKJEhISdO211yohISEs94UxRm63W9u3b9fhw4e1ZcuWoO/i7Nu3Tzk5Ofrpp5+Un5/vcE2dY/cB/fr1U506dZSSkqLrrrsupHVcc801SktLU82aNTVgwAAnqnlWeL1e1alTR5ZlKSYmRikpKSHdJa9fv75cLlegbLD9a3Vi/v+J2FatWulvf/ub7r77bmVmZgZdNjIyUoMGDVKNGjXUsmVLde7c2eEaA7+0vf/4j/9QSkqKMjIy1KJFi5CeUiktLdXPP/8sj8ej9PR0RUREOFhbZw0YMEA9evRQ3759Q4rz2rZtq7p168qyLNWrV09t27Z1uKbOsGP3m266SVlZWbrpppsUHR0dVFnLslS/fn2lpqYqJSVFl19+eVjGNtK/47yEhATdd999uvjii0Mq36ZNG2VlZal27dq68cYbwzbOs+3evTvwBKD9tsPpHD16VMXFxYEnhEpKSsL2ui4R59kaNGggr9cry7LUuHHjoI+p3+9XgwYNlJSUpOTkZF1//fWSFJZtQvrlzY2hQ4fquuuuU4cOHUIq26NHDzVo0EAtW7ZUx44dHaphaKrFq3aStHbtWh06dEiJiYlatmxZSI+DHTx4UMOHD1fHjh01ffr0sHvc9nilpaVyu93y+Xzy+XxBX0Q2b96s/fv3KyUlRcuXL1dRUVHYXoByc3N1yy23qGvXrpoxY0bQ5SzL0pEjR3TrrbcqMzMzrNtDfn6+1qxZo4yMDP3444/atWtXSOV//PFH7d69W2lpaVq1apWOHj0alu3B7/erpKRE7777rlavXq19+/bp8OHDQZVds2aNevTooeLiYuXk5DhcU+f4/X653W6tWLFCgwYNkmVZ+vbbb4Mq63K55Pf7tXz5cg0bNkxut1vffPONwzV2zuHDh/Xss89qxIgR2rhxoxYvXhx4beN0gcWxY8f01FNP6c4779T27dv1ySefhGX/YP7/9cANGzbo1VdfVb169bRkyZKgytqv9vzrX/9Ss2bNdOjQobB+ZQnhwxijadOmqUmTJlq9erVWrVoVUnmfz6cJEyZow4YN2r59uw4ePOhQTZ2Xn58fuB6HEud99tln+uc//6lu3bpp3bp1+vbbb8Pyuu5yuZSbm6vnn39ew4YNU3Z2to4ePRq4Xp2K3+/XF198odtvv13NmjXTq6++Gpb9uGVZ8vl8OnLkiBITE5Wfn68DBw6EtI5jx47J5/MpMjJSx44dk9/vD/p6WN2UlpbqnXfeUWFhoZKTk/X2228HVW7RokW688471bRpU82bN08FBQUO19QZZeM8+wGMNWvWBFXWPm/s5UtLS7Vs2TInq+u4d955R926dZPL5dKXX34pKfjxv1auXKmCggIVFxfrzTffdLKajvP5fJo4caLq1q2r999/P6gydn/43nvv6dprr5UxRhs2bHCymkGzTBA9U35+vhITEx2rhMvlktvtVuvWrZWYmKjVq1fr8OHDQb3Xao8bYHe0paWlYfluc1kNGjTQ3XffLWOMnn76ae3Zs6fcGAAnY1mWWrdurdTUVH3//feBoCwc32u1j6nb7Q4kIYMdw8Uu63K55PP5wrI92NtQt25dnXfeedqzZ482b94c1DlRVsuWLZWWlqZ169aVG/8s3PbHb53b7Zbb7ZbL5VL79u1lWZZWrFgRVIBltyWPx6N27drJ4/Ho22+/VWFh4VmouTOioqICfYP99Fsw7drj8QTGN5IUKGv3E+EoMjJSLpdLRUVFQX358ng8sixL8fHxuvDCC5Wbm6vvv/8+5L4lVHl5eUpISHD0M1B5ZyvOs59KLi0tVXFxcchjTpSN95xus06qU6eOhg4dKmOMXn/9deXk5AQV50m/9H+tWrXSli1bVFBQEOj7wqkPs2M0j8cT6Mt9Pl9Q7cE+/nZbsLc/3JJP9nX94osv1pAhQzR//nx98skngfFZg+H1enXVVVcpKytL77zzjhYsWBCW7aEsO/a3j+nptsPtdgd+rhZj2FRS2TivXbt2ioyM1Lp164J68ss+F2rUqKGLLrpIJSUlWrZsWWBs13Bjx6xlx8ELduznsufVsWPHtH79ehljwvp64Xa7y92oCJZlWYqNjZUkFRcXh9S3VEYwcV61SDzZnUzZC0iwg6XaFx/7Z7vTCdcOV/rli4F918LOYgdzUbVPVLusvQ/CMdFQ9rjagg1IyraHcL0A21+M7Xrb7SCUi+q51B5+6+zAquzdHvupl9Mp+0XNXkeobak6sdv18ed1sNcLO6Ate2c9nM+J4798nc7xbcm+bjr9pY3EU/V2NhJPx/df9nUplLZX9hofrn2YVP6LRKjJE7v/s/uwcOy/7GtS2RuMdp8eTD8u/bIP7f1VNv4PF/Zg+9K/Y73KJFTttmS3o3BsD2WVbRvBDiZtlwu3NlBW2QSa9O9hJoIZWuL4OC/YpF11dqJrRrD9g53AK/sdMNwS02WV3RehtnF76KJgvzP8GmGTeAIAAOcuEk/VG3EeAACorGDivGoxuDgAAAAAAADOPSSeAAAAAAAA4AgSTwAAAAAAAHAEiScAAAAAAAA4gsQTAAAAAAAAHEHiCQAAAAAAAI4g8QQAAAAAAABHkHgCAAAAAACAI0g8AQAAAAAAwBEkngAAAAAAAOAIEk8AAAAAAABwBIknAAAAAAAAOILEEwAAAAAAABxB4gkAAAAAAACOIPEEAAAAAAAAR5B4AgAAAAAAgCNIPAEAAAAAAMARJJ4AAAAAAADgCBJPAAAAAAAAcASJJwAAAAAAADiCxBMAAAAAAAAcQeIJAAAAAAAAjiDxBAAAAAAAAEeQeAIAAAAAAIAjSDwBAAAAAADAESSeAAAAAAAA4AgSTwAAAAAAAHAEiScAAAAAAAA4gsQTAAAAAAAAHEHiCQAAAAAAAI4g8QQAAAAAAABHkHgCAAAAAACAI0g8AQAAAAAAwBEkngAAAAAAAOCIoBJPxhin6wEAAM5RxBHVG8cHAABUVjBxRFCJp8OHD//qygAAgN8m4ojqjeMDAAAqK5g4wjJBpKf8fr92796t+Ph4WZZ1RioHAADObcYYHT58WPXq1ZPLxdv91RVxHgAACFUocV5QiScAAAAAAAAgVNx+BAAAAAAAgCNIPAEAAAAAAMARJJ4AAAAAAADgCBJPAAAAAAAAcASJJwAAAAAAADiCxBMAAAAAAAAcQeIJAAAAAAAAjvg/2uMRgqWC1/UAAAAASUVORK5CYII=\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1TXOpEggcwig"
      },
      "execution_count": 16,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}